{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: / \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/osx-64::pytest-astropy==0.5.0=py37_0\n",
      "  - defaults/osx-64::pytest-arraydiff==0.3=py37h39e3cac_0\n",
      "  - defaults/osx-64::anaconda==2019.07=py37_0\n",
      "  - defaults/osx-64::pytest-doctestplus==0.3.0=py37_0\n",
      "  - defaults/noarch::conda-verify==3.4.2=py_1\n",
      "  - defaults/osx-64::conda-build==3.18.8=py37_0\n",
      "  - defaults/osx-64::pytest-openfiles==0.3.2=py37_0\n",
      "  - defaults/osx-64::pytest-remotedata==0.3.1=py37_0\n",
      "  - defaults/osx-64::astropy==3.2.1=py37h1de35cc_0\n",
      "  - defaults/osx-64::conda-package-handling==1.7.2=py37h22f3db7_0\n",
      "  - defaults/osx-64::conda==4.7.10=py37_0\n",
      "  - defaults/noarch::path.py==12.0.1=py_0\n",
      "  - defaults/osx-64::pytest==5.0.1=py37_0\n",
      "  - defaults/noarch::pluggy==0.12.0=py_0\n",
      "failed with current_repodata.json, will retry with next repodata source.\n",
      "Initial quick solve with frozen env failed.  Unfreezing env and trying again.\n",
      "Solving environment: failed with current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): \\ "
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design a Quiz\n",
      "Which book would you like to use?\n",
      "Here are your choices:\n",
      "\n",
      "The Best Bad Luck I Ever Had \n",
      " The Lions of Little Rock\n",
      " The Paper Cowboy\n",
      " The Thing I'm Most Afraid Of\n",
      " Anne of Green Gables\n",
      "Anne of Green Gables\n"
     ]
    }
   ],
   "source": [
    "#Gathering info from a user\n",
    "print(\"Design a Quiz\")\n",
    "print(\"Which book would you like to use?\")\n",
    "print (\"Here are your choices:\\n\")\n",
    "print(\"The Best Bad Luck I Ever Had \\n The Lions of Little Rock\\n The Paper Cowboy\\n The Thing I'm Most Afraid Of\\n Anne of Green Gables\")\n",
    "book = input()\n",
    "if book == \"The Best Bad Luck I Ever Had\":\n",
    "    narrator = \"Dit\"\n",
    "    text = \"Book_1\"\n",
    "elif book == \"The Lions of Little Rock\":\n",
    "    narrator = \"Marlee\"\n",
    "    text = \"Book_2\"\n",
    "elif book == \"The Paper Cowboy\":\n",
    "    narrator = \"Tommy\"\n",
    "    text = \"Book_3\"\n",
    "elif book == \"The Thing I'm Most Afraid Of\":\n",
    "    narrator = \"Becca\"\n",
    "    text = \"Book_4\"\n",
    "elif book == \"Anne of Green Gables\":\n",
    "    narrator = ''\n",
    "    text = \"Book_5\"\n",
    "else:\n",
    "    print(\"I'm sorry. That book is not in our database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is deprecated as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9a7eb073c915>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Creating the file dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, disable, exclude, config)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \"\"\"\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is deprecated as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")"
     ]
    }
   ],
   "source": [
    "#Creating a file dictionary\n",
    "#This assumes the files are broken down into chapters in a folder\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "#Creating the file dictionary\n",
    "# point this to the data directory\n",
    "direc = \"/Users/kristinlevine/Desktop/NLP_Project/\" + text \n",
    "ext = '.txt' # Select your file delimiter\n",
    "\n",
    "file_dict = {} # Create an empty dict\n",
    "\n",
    "# Select only files with the ext extension\n",
    "txt_files = [i for i in os.listdir(direc) if os.path.splitext(i)[1] == ext]\n",
    "\n",
    "# Iterate over your txt files\n",
    "for f in txt_files:\n",
    "    # Open them and assign them to file_dict\n",
    "    with open(os.path.join(direc,f)) as file_object:\n",
    "        file_dict[f] = file_object.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\", len(txt_files), 'chapters in this book.')\n",
    "print(\"Which chapter would you like to analyze?\")\n",
    "chapter = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To extract persons and locations\n",
    "def extract_entities(doc_id, doc_text):\n",
    "    analyzed_doc = nlp(doc_text)\n",
    "\n",
    "    doc_persons = {}\n",
    "    doc_locations = {}\n",
    "    \n",
    "    for entity in analyzed_doc.ents:\n",
    "        if entity.text.strip() != \"\" and entity.label_ == \"PERSON\":\n",
    "            prev_token = analyzed_doc[entity.start-1]\n",
    "            if prev_token.text in (\"Doc\", \"Dr.\", \"Mr.\", \"Mrs.\", 'Ms.'):\n",
    "                name = prev_token.text + ' '+ entity.text.strip()\n",
    "                if name not in doc_persons.keys():\n",
    "                    relevant_sentence = (doc_id, entity.sent.text)\n",
    "                    doc_persons[name] = list()\n",
    "                if name in doc_persons.keys():\n",
    "                    relevant_sentence = (doc_id, entity.sent.text)\n",
    "                    doc_persons[name].append(relevant_sentence)  \n",
    "            else:\n",
    "                if entity.text.strip() not in doc_persons.keys():\n",
    "                    relevant_sentence = (doc_id, entity.sent.text)\n",
    "                    doc_persons[entity.text.strip()] = list()\n",
    "                \n",
    "                if entity.text.strip() in doc_persons.keys():\n",
    "                    relevant_sentence = (doc_id, entity.sent.text)\n",
    "                    doc_persons[entity.text.strip()].append(relevant_sentence)  \n",
    "                \n",
    "    for entity in analyzed_doc.ents:\n",
    "        if entity.text.strip() != \"\" and (entity.label_ == 'LOC' or entity.label_ == \"GPE\"):\n",
    "            \n",
    "            if entity.text.strip() not in doc_locations.keys():\n",
    "                relevant_sentence = (doc_id, entity.sent.text)\n",
    "                doc_locations[entity.text.strip()] = list()\n",
    "                \n",
    "            if entity.text.strip() in doc_locations.keys():\n",
    "                relevant_sentence = (doc_id, entity.sent.text)\n",
    "                doc_locations[entity.text.strip()].append(relevant_sentence)  \n",
    "            \n",
    "    return doc_persons, doc_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_popular_entities(entity_dictionary):\n",
    "    \n",
    "    list_most_mentions = {}\n",
    "    \n",
    "    for entity in entity_dictionary:\n",
    "        x = []\n",
    "        for i in range(len(entity_dictionary[entity])):\n",
    "            x.append(len(entity_dictionary[entity][i]))\n",
    "        list_most_mentions[entity] = sum(x)\n",
    "        \n",
    "    # sort through the entities in the dictionary by the number of sentences\n",
    "    \n",
    "    return list_most_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Emma Walker': 2, 'Harry Otis': 2, 'Dit': 6, 'Ollie': 2, 'Raymond': 2, 'Earl': 2, 'Pearl': 2, 'Robert': 2, 'Lois': 2, 'Mrs. Pooley': 10, 'Goods Store': 2, 'Uncle': 6, 'Robert E. Lee': 2, 'Lee': 4, 'Mr. Walker': 2}\n"
     ]
    }
   ],
   "source": [
    "a, b = extract_entities(chapter + '.txt', file_dict[chapter +'.txt'])\n",
    "tp = find_most_popular_entities(a)\n",
    "tl = find_most_popular_entities(b)\n",
    "print(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Persons\n",
    "if len(tp) > 0:\n",
    "    chapter_persons = pd.DataFrame.from_dict(tp, orient = 'index')\n",
    "    chapter_persons = chapter_persons.rename(columns = {0:'Count'})\n",
    "    chapter_persons = chapter_persons.sort_values(by=['Count'], ascending = False)\n",
    "#print(chapter_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locations\n",
    "if len(tl) > 0:\n",
    "    chapter_locations = pd.DataFrame.from_dict(tl, orient = 'index')\n",
    "    chapter_locations = chapter_locations.rename(columns = {0:'Count'})\n",
    "    chapter_locations = chapter_locations.sort_values(by=['Count'], ascending = False)\n",
    "else:\n",
    "    chapter_locations = []\n",
    "#print(chapter_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_persons = {}\n",
    "combined_locations = {}\n",
    "\n",
    "for item in txt_files: \n",
    "    persons, locations = extract_entities(item, file_dict[item])\n",
    "\n",
    "#For Persons\n",
    "    for per in persons.keys():\n",
    "        if per not in combined_persons.keys():\n",
    "            combined_persons[per] = list()\n",
    "        \n",
    "        if per in combined_persons.keys():\n",
    "            combined_persons[per].append(persons.get(per))\n",
    "\n",
    "#For Locations\n",
    "    for loc in locations.keys():\n",
    "        if loc not in combined_locations.keys():\n",
    "            combined_locations[loc] = list()\n",
    "        \n",
    "        if loc in combined_locations.keys():\n",
    "            combined_locations[loc].append(locations.get(loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Emma', 'Dr. Griffith', 'Elbert', 'Mrs. Walker', 'Bobby', 'Doc', 'Mr. Walker', 'Pearl', 'Doc Haley', 'Mrs. Pooley', 'Raymond', 'Mrs. Seay', 'Chip', 'Mama', 'Davidson', 'Earl', 'Mary', 'Uncle', 'Robert', 'Jim', 'Lois', 'Jim Dang', 'Jim Dang-It', 'Della', 'Ulman', 'Elman', 'Mr. Fulton']\n"
     ]
    }
   ],
   "source": [
    "#Creating a List of the top characters in the book\n",
    "all_characters = find_most_popular_entities(combined_persons)\n",
    "char_in_book = pd.DataFrame.from_dict(all_characters, orient = 'index')\n",
    "char_in_book = char_in_book.rename(columns = {0:\"Count\"})\n",
    "char_in_book = char_in_book.sort_values(by=['Count'], ascending = False)\n",
    "main_char = char_in_book.head(30)\n",
    "people = main_char.index.tolist()\n",
    "#We also need to remove the narrator from this list because he/she can't talk to him/herself.\n",
    "words_remove = ['Moundville', \"Negra\"]\n",
    "if narrator in people:\n",
    "    people.remove(narrator)\n",
    "else: \n",
    "    pass\n",
    "\n",
    "for m in words_remove:\n",
    "    if m in people:\n",
    "        people.remove(m)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Moundville', 'Selma', 'Boston', 'Alabama', 'the Black Warrior', 'South', 'Chicago', 'Negras', 'Treasure Island', 'Kentucky', 'Massachusetts', 'New York', 'Haley', 'Albany', 'the United States', 'Germany']\n"
     ]
    }
   ],
   "source": [
    "#Creating a List of the top 20 locations in the book\n",
    "all_locations = find_most_popular_entities(combined_locations)\n",
    "loc_in_book = pd.DataFrame.from_dict(all_locations, orient = 'index')\n",
    "loc_in_book = loc_in_book.rename(columns = {0:\"Count\"})\n",
    "loc_in_book = loc_in_book.sort_values(by=['Count'], ascending = False)\n",
    "main_loc = loc_in_book.head(20)\n",
    "location = main_loc.index.tolist()\n",
    "words_to_remove = [\"ain’t\", 'Lover', \"Cordelia\", '☺', \"A.M.\", \"Curtis\", \"Negro\", \"Red\", \"a.k.a\", \"Busia\"]\n",
    "\n",
    "for i in people:\n",
    "    if i in location:\n",
    "        location.remove(i)\n",
    "    elif narrator in location:\n",
    "        location.remove(narrator)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for j in words_to_remove:\n",
    "    if j in location:\n",
    "        location.remove(j)\n",
    "    else: \n",
    "        pass\n",
    "        \n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the characters/locations in each chapters against the main_character/locations list.\n",
    "#This makes sure we are asking about a fairly major character/location; not someone/someplace who is mentioned only once.\n",
    "\n",
    "chapter_characters = []\n",
    "for i in range(len(chapter_persons)):\n",
    "    for x in people:\n",
    "        if chapter_persons.index[i] == x:\n",
    "            chapter_characters.append(chapter_persons.index[i])\n",
    "        else:\n",
    "            pass    \n",
    "    \n",
    "chapter_loc = []\n",
    "for i in range(len(chapter_locations)):\n",
    "    for x in location:\n",
    "        if chapter_locations.index[i] == x:\n",
    "            chapter_loc.append(chapter_locations.index[i])\n",
    "        else:\n",
    "            pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mrs. Pooley', 'Uncle', 'Raymond', 'Earl', 'Pearl', 'Robert', 'Lois', 'Mr. Walker']\n",
      "['Moundville', 'Alabama', 'Selma']\n"
     ]
    }
   ],
   "source": [
    "print(chapter_characters)\n",
    "print(chapter_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Thing I'm Most Afraid Of\n",
      "Chapter 1 : Questions for Discussion\n",
      "What did Becca talk about with Dr. Teresa ?\n",
      "What did Becca and Chrissy discuss?\n",
      "Why is Austria mentioned in this chapter?\n"
     ]
    }
   ],
   "source": [
    "print(book)\n",
    "print(\"Chapter\", chapter, \": Questions for Discussion\")\n",
    "\n",
    "\n",
    "#This accounts for if the book has a narrator or not:\n",
    "if narrator == \"\":\n",
    "    narrator = chapter_characters[0]\n",
    "    i = 1\n",
    "else:\n",
    "    i = 0\n",
    "\n",
    "#This will print up to three character questions per chapter\n",
    "if len(chapter_characters) == 0:\n",
    "    pass\n",
    "elif len(chapter_characters) == 1:\n",
    "    print(\"What did\", narrator, \"talk about with\", chapter_characters[i], \"?\")\n",
    "elif len(chapter_characters) == 2:\n",
    "    print(\"What did\", narrator, \"talk about with\", chapter_characters[i], \"?\")\n",
    "    print(\"What did\", narrator, \"and\", chapter_characters[i+1], \"discuss?\")\n",
    "else:\n",
    "    print(\"What did\", narrator, \"talk about with\", chapter_characters[i], \"?\")\n",
    "    print(\"What did\", narrator, \"and\", chapter_characters[i+1], \"discuss?\")\n",
    "    print(\"What did\", narrator, \"say to\", chapter_characters[i+2], \"?\")\n",
    "    \n",
    "#This will print a location question:\n",
    "if len(chapter_loc) == 0:\n",
    "    pass\n",
    "else:\n",
    "    print(\"Why is\", chapter_loc[0], \"mentioned in this chapter?\")\n",
    "    \n",
    "# We'd print these questions, any vocab words, etc, to a pdf that the user could then print out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to figure out how to deal with characters with prefixes \"Mrs. Walker\" vs. \"Walker\"\n",
    "#We'd write these questions to a pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
