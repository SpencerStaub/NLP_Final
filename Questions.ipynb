{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design a Quiz\n",
      "Which book would you like to use?\n",
      "Here are your choices:\n",
      "\n",
      "The Best Bad Luck I Ever Had \n",
      " The Lions of Little Rock\n",
      " The Paper Cowboy\n",
      " The Thing I'm Most Afraid Of\n",
      " Anne of Green Gables\n",
      "The Best Bad Luck I Ever Had\n"
     ]
    }
   ],
   "source": [
    "#Gathering info from a user\n",
    "print(\"Design a Quiz\")\n",
    "print(\"Which book would you like to use?\")\n",
    "print (\"Here are your choices:\\n\")\n",
    "print(\"The Best Bad Luck I Ever Had \\n The Lions of Little Rock\\n The Paper Cowboy\\n The Thing I'm Most Afraid Of\\n Anne of Green Gables\")\n",
    "book = input()\n",
    "if book == \"The Best Bad Luck I Ever Had\":\n",
    "    narrator = \"Dit\"\n",
    "    text = \"Book_1\"\n",
    "elif book == \"The Lions of Little Rock\":\n",
    "    narrator = \"Marlee\"\n",
    "    text = \"Book_2\"\n",
    "elif book == \"The Paper Cowboy\":\n",
    "    narrator = \"Tommy\"\n",
    "    text = \"Book_3\"\n",
    "elif book == \"The Thing I'm Most Afraid Of\":\n",
    "    narrator = \"Becca\"\n",
    "    text = \"Book_4\"\n",
    "elif book == \"Anne of Green Gables\":\n",
    "    narrator = ''\n",
    "    text = \"Book_5\"\n",
    "else:\n",
    "    print(\"I'm sorry. That book is not in our database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a file dictionary\n",
    "#This assumes the files are broken down into chapters in a folder\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "#Creating the file dictionary\n",
    "# point this to the data directory\n",
    "direc = \"/Users/kristinlevine/Desktop/NLP_Project/\" + text \n",
    "ext = '.txt' # Select your file delimiter\n",
    "\n",
    "file_dict = {} # Create an empty dict\n",
    "\n",
    "# Select only files with the ext extension\n",
    "txt_files = [i for i in os.listdir(direc) if os.path.splitext(i)[1] == ext]\n",
    "\n",
    "# Iterate over your txt files\n",
    "for f in txt_files:\n",
    "    # Open them and assign them to file_dict\n",
    "    with open(os.path.join(direc,f)) as file_object:\n",
    "        file_dict[f] = file_object.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 62 chapters in this book.\n",
      "Which chapter would you like to analyze?\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(txt_files), 'chapters in this book.')\n",
    "print(\"Which chapter would you like to analyze?\")\n",
    "chapter = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To extract \n",
    "def extract_entities(doc_id, doc_text):\n",
    "    analyzed_doc = nlp(doc_text)\n",
    "\n",
    "    doc_persons = {}\n",
    "    \n",
    "    for entity in analyzed_doc.ents:\n",
    "        if entity.text.strip() != \"\" and entity.label_ == \"PERSON\":\n",
    "            \n",
    "            if entity.text.strip() not in doc_persons.keys():\n",
    "                relevant_sentence = (doc_id, entity.sent.text)\n",
    "                doc_persons[entity.text.strip()] = list()\n",
    "                \n",
    "            if entity.text.strip() in doc_persons.keys():\n",
    "                relevant_sentence = (doc_id, entity.sent.text)\n",
    "                doc_persons[entity.text.strip()].append(relevant_sentence)  \n",
    "            \n",
    "    return doc_persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_popular_entities(entity_dictionary):\n",
    "    \n",
    "    list_most_mentions = {}\n",
    "    \n",
    "    for entity in entity_dictionary:\n",
    "        x = []\n",
    "        for i in range(len(entity_dictionary[entity])):\n",
    "            x.append(len(entity_dictionary[entity][i]))\n",
    "        list_most_mentions[entity] = sum(x)\n",
    "        \n",
    "    # sort through the entities in the dictionary by the number of sentences\n",
    "    \n",
    "    return list_most_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = extract_entities(chapter + '.txt', file_dict[chapter +'.txt'])\n",
    "tp = find_most_popular_entities(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Persons\n",
    "chapter_persons = pd.DataFrame.from_dict(tp, orient = 'index')\n",
    "chapter_persons = chapter_persons.rename(columns = {0:'Count'})\n",
    "chapter_persons = chapter_persons.sort_values(by=['Count'], ascending = False)\n",
    "#print(chapter_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_persons = {}\n",
    "\n",
    "for item in txt_files: \n",
    "    persons = extract_entities(item, file_dict[item])\n",
    "\n",
    "#For Persons\n",
    "    for per in persons.keys():\n",
    "        if per not in combined_persons.keys():\n",
    "            combined_persons[per] = list()\n",
    "        \n",
    "        if per in combined_persons.keys():\n",
    "            combined_persons[per].append(persons.get(per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a List of the top 20 characters in the book\n",
    "all_characters = find_most_popular_entities(combined_persons)\n",
    "char_in_book = pd.DataFrame.from_dict(all_characters, orient = 'index')\n",
    "char_in_book = char_in_book.rename(columns = {0:\"Count\"})\n",
    "char_in_book = char_in_book.sort_values(by=['Count'], ascending = False)\n",
    "main_char = char_in_book.head(21)\n",
    "people = main_char.index.tolist()\n",
    "#We also need to remove the narrator from this list because he/she can't talk to him/herself.\n",
    "if narrator in people:\n",
    "    people.remove(narrator)\n",
    "else: \n",
    "    pass\n",
    "#print(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the characters in each chapters against the main_character (people) list.\n",
    "#This makes sure we are asking about a fairly major characters; not someone who is mentioned only once.\n",
    "\n",
    "chapter_characters = []\n",
    "for i in range(len(chapter_persons)):\n",
    "    for x in people:\n",
    "        if chapter_persons.index[i] == x:\n",
    "            chapter_characters.append(chapter_persons.index[i])\n",
    "        else:\n",
    "            pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Bad Luck I Ever Had\n",
      "Chapter 33 : Questions for Discussion\n",
      "What did Dit talk about with Raymond ?\n",
      "What did Dit and Emma discuss?\n",
      "What did Dit say to Pooley ?\n"
     ]
    }
   ],
   "source": [
    "print(book)\n",
    "print(\"Chapter\", chapter, \": Questions for Discussion\")\n",
    "\n",
    "\n",
    "#This accounts for if the book has a narrator or not:\n",
    "if narrator == \"\":\n",
    "    narrator = chapter_characters[0]\n",
    "    i = 1\n",
    "else:\n",
    "    i = 0\n",
    "\n",
    "#This will print up to three character questions per chapter\n",
    "if len(chapter_characters) == 0:\n",
    "    pass\n",
    "elif len(chapter_characters) == 1:\n",
    "    print(\"What did\", narrator, \"talk about with\", chapter_characters[i], \"?\")\n",
    "elif len(chapter_characters) == 2:\n",
    "    print(\"What did\", narrator, \"talk about with\", chapter_characters[i], \"?\")\n",
    "    print(\"What did\", narrator, \"and\", chapter_characters[i+1], \"discuss?\")\n",
    "else:\n",
    "    print(\"What did\", narrator, \"talk about with\", chapter_characters[i], \"?\")\n",
    "    print(\"What did\", narrator, \"and\", chapter_characters[i+1], \"discuss?\")\n",
    "    print(\"What did\", narrator, \"say to\", chapter_characters[i+2], \"?\")\n",
    "    \n",
    "# We'd print these questions, any vocab words, etc, to a pdf that the user could then print out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to figure out how to deal with characters with prefixes \"Mrs. Walker\" vs. \"Walker\"\n",
    "#We'd write these questions to a pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
