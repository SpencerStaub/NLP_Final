{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "separated-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import collections as c\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.add_pipe('spacytextblob')\n",
    "all_stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broken-strength",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapter_number</th>\n",
       "      <th>chapter_title</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>entity</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chapter 1</td>\n",
       "      <td>THE NEW POSTMASTER</td>\n",
       "      <td>wrong</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>wrong</td>\n",
       "      <td>JJ</td>\n",
       "      <td>acomp</td>\n",
       "      <td>\\n      I’ve been wrong before.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chapter 1</td>\n",
       "      <td>THE NEW POSTMASTER</td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td></td>\n",
       "      <td>_SP</td>\n",
       "      <td>ROOT</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chapter 1</td>\n",
       "      <td>THE NEW POSTMASTER</td>\n",
       "      <td>Oh</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>oh</td>\n",
       "      <td>UH</td>\n",
       "      <td>intj</td>\n",
       "      <td>Oh heck, if I’m being real honest, I’ve been w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chapter 1</td>\n",
       "      <td>THE NEW POSTMASTER</td>\n",
       "      <td>heck</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>heck</td>\n",
       "      <td>UH</td>\n",
       "      <td>intj</td>\n",
       "      <td>Oh heck, if I’m being real honest, I’ve been w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chapter 1</td>\n",
       "      <td>THE NEW POSTMASTER</td>\n",
       "      <td>real</td>\n",
       "      <td>ADV</td>\n",
       "      <td>real</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>Oh heck, if I’m being real honest, I’ve been w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chapter_number       chapter_title tokens    pos  lemma  tag     dep  \\\n",
       "0      Chapter 1  THE NEW POSTMASTER  wrong    ADJ  wrong   JJ   acomp   \n",
       "1      Chapter 1  THE NEW POSTMASTER         SPACE         _SP    ROOT   \n",
       "2      Chapter 1  THE NEW POSTMASTER     Oh   INTJ     oh   UH    intj   \n",
       "3      Chapter 1  THE NEW POSTMASTER   heck   INTJ   heck   UH    intj   \n",
       "4      Chapter 1  THE NEW POSTMASTER   real    ADV   real   RB  advmod   \n",
       "\n",
       "                                            sentence word entity title  \n",
       "0                    \\n      I’ve been wrong before.  NaN    NaN   NaN  \n",
       "1                                                     NaN    NaN   NaN  \n",
       "2  Oh heck, if I’m being real honest, I’ve been w...  NaN    NaN   NaN  \n",
       "3  Oh heck, if I’m being real honest, I’ve been w...  NaN    NaN   NaN  \n",
       "4  Oh heck, if I’m being real honest, I’ve been w...  NaN    NaN   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('book_1.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tribal-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_num = 2\n",
    "C_num = str(C_num)\n",
    "\n",
    "#chapter_df = df[df['chapter_number'] ==  'Chapter '+ C_num]\n",
    "#persons_df = chapter_df[chapter_df['entity'] == 'PERSON']\n",
    "\n",
    "persons_df = df[df['entity'] == 'PERSON']\n",
    "persons_count_df = persons_df.groupby(by = ['word']).count().reset_index()\n",
    "persons_count_df = persons_count_df.drop(['chapter_number','chapter_title','tokens','lemma','tag','dep','pos','title','sentence'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spare-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Emma</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Walker</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Elbert</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dit</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Griffith</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Seay</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Pearl</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bobby</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Haley</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pooley</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  entity\n",
       "14      Emma     740\n",
       "55    Walker     190\n",
       "11    Elbert     142\n",
       "9        Dit     138\n",
       "18  Griffith     131\n",
       "46      Seay     116\n",
       "40     Pearl      95\n",
       "4      Bobby      95\n",
       "19     Haley      89\n",
       "41    Pooley      73"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons_count_df.sort_values(by = 'entity', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unlike-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    " # convert list to string \n",
    "def listToString(s): \n",
    "    str1 = \"\"  \n",
    "    for item in s: \n",
    "        str1 += item\n",
    "        str1 += ' '\n",
    "    return str1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "loving-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_sentence = persons_df['sentence'].unique().tolist()\n",
    "persons_string = listToString(persons_sentence)\n",
    "\n",
    "persons_word = persons_df['word'].unique().tolist()\n",
    "terms = []\n",
    "for persons in persons_word:\n",
    "    terms.append(\"{} said\".format(persons))\n",
    "    terms.append(\"said {}\".format(persons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "authentic-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "patterns = [nlp.make_doc(text) for text in terms]\n",
    "matcher.add(\"TerminologyList\", patterns)\n",
    "\n",
    "doc = nlp(persons_string)\n",
    "\n",
    "matches = matcher(doc)\n",
    "spoken_persons = []\n",
    "for match_id, start, end in matches:\n",
    "    span = str(doc[start:end])\n",
    "    span2 = span.replace(' said', '')\n",
    "    span3 = span2.replace('said ', '')\n",
    "    spoken_persons.append(span3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "solid-formation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emma</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elbert</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bobby</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Seay</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Walker</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pearl</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Griffith</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Raymond</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Haley</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ulman</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Elman</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pooley</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Earl</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Billy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Davidson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wiggens</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tommy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  Count\n",
       "1       Emma     72\n",
       "4     Elbert     13\n",
       "9      Bobby     11\n",
       "10      Seay     11\n",
       "2     Walker      8\n",
       "8      Pearl      7\n",
       "13  Griffith      7\n",
       "5    Raymond      6\n",
       "15     Haley      2\n",
       "3      Ulman      2\n",
       "6      Elman      2\n",
       "11    Pooley      2\n",
       "14      Earl      2\n",
       "17     Billy      1\n",
       "16  Davidson      1\n",
       "0        Lee      1\n",
       "12   Wiggens      1\n",
       "7        Jim      1\n",
       "18     Tommy      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spoken_dict = c.Counter(spoken_persons)\n",
    "spoken_df = pd.DataFrame.from_dict(spoken_dict, orient='index', columns = ['Count']).reset_index()\n",
    "spoken_df.sort_values(by = 'Count', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "breeding-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "spoken_hurdle = spoken_df[spoken_df['Count'] > 3]\n",
    "spoken_hurdle = spoken_hurdle['index'].tolist()\n",
    "mention_hurdle = persons_count_df[persons_count_df['entity'] > 10]\n",
    "mention_hurdle = mention_hurdle['word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "infrared-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_person (person_list):\n",
    "    book_characters = []\n",
    "    for person in person_list:\n",
    "        if person in spoken_hurdle:\n",
    "            book_characters.append(person)\n",
    "        elif person in mention_hurdle:\n",
    "            book_characters.append(person)\n",
    "            \n",
    "    return book_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "affected-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_list1 = persons_df['word'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "relative-colony",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emma',\n",
       " 'Walker',\n",
       " 'Sims',\n",
       " 'Dit',\n",
       " 'Ollie',\n",
       " 'Ulman',\n",
       " 'Elman',\n",
       " 'Raymond',\n",
       " 'Earl',\n",
       " 'Pearl',\n",
       " 'Robert',\n",
       " 'Lois',\n",
       " 'Pooley',\n",
       " 'Wiggens',\n",
       " 'Elbert',\n",
       " 'Davidson',\n",
       " 'Haley',\n",
       " 'Griffith',\n",
       " 'Jim',\n",
       " 'Dang',\n",
       " 'Mitch',\n",
       " 'Seay',\n",
       " 'Bobby',\n",
       " 'Mary']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book1_characters = check_person (persons_list1)\n",
    "\n",
    "book1_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "solved-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then on chapter you have a persons list and you compare to the book character list\n",
    "# if it is in the list then that is a character for the chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-combining",
   "metadata": {},
   "source": [
    "## Locations and Organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "married-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_entity_df = df.loc[(df['entity'] == 'LOC' ) | (df['entity'] == 'GPE' )]\n",
    "oth_entity_count_df = oth_entity_df.groupby(by = ['word']).count().reset_index()\n",
    "oth_entity_count_df = oth_entity_count_df.drop(['chapter_number','chapter_title','tokens','lemma','tag','dep','pos','title','sentence'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "configured-disclosure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Moundville</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Selma</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boston</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pa.</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>South</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Tuscaloosa</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>North</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  entity\n",
       "19  Moundville      37\n",
       "24       Selma      26\n",
       "5       Boston      23\n",
       "21         Pa.      15\n",
       "1      Alabama      10\n",
       "25       South       6\n",
       "26  Tuscaloosa       5\n",
       "7      Chicago       4\n",
       "20       North       4\n",
       "16    Kentucky       2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oth_entity_count_df.sort_values(by = 'entity', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pregnant-conditioning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " 'PERSON',\n",
       " 'GPE',\n",
       " 'DATE',\n",
       " 'ORG',\n",
       " 'TIME',\n",
       " 'PRODUCT',\n",
       " 'LOC',\n",
       " 'CARDINAL',\n",
       " 'NORP',\n",
       " 'WORK_OF_ART',\n",
       " 'ORDINAL',\n",
       " 'MONEY',\n",
       " 'LANGUAGE']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['entity'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "searching-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locations in the sense we would be looking for peoples houses, school, offices, libraries etc. do not get picked up by entities, \n",
    "#Probably best to create list of common location names we are interested in. \n",
    "#Challenge will be in some cases we would want the preceding words and others we will not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "native-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noun = df[df['pos'] == 'NOUN']\n",
    "\n",
    "sentences = df_noun['sentence'].unique().tolist()\n",
    "\n",
    "sentence_string = listToString(sentences)\n",
    "\n",
    "doc = nlp(sentence_string )\n",
    "\n",
    "noun_chunks = []\n",
    "for chunk in doc.noun_chunks:\n",
    "    noun_chunks.append(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "imposed-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_nouns = ['house', 'office', 'church', 'castle', 'river', 'creek', 'beach', 'ocean','palace',\n",
    "               'forest', 'woods','mountains', 'stream', 'fields', 'store', 'school', 'hill', 'home', 'zoo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "particular-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_places = []\n",
    "for chunk in noun_chunks:\n",
    "    for place in place_nouns:\n",
    "        if place in chunk:\n",
    "            common_places.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "competent-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_dict = c.Counter(common_places)\n",
    "\n",
    "place_df = pd.DataFrame.from_dict(place_dict , orient='index', columns = ['Count']).reset_index()\n",
    "\n",
    "place_df = place_df.rename(columns = {'index' : 'word', 'Count' : 'entity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "junior-velvet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>school</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Moundville</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Selma</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boston</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>the river</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pa.</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mrs. Pooley’s store</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>home</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the woods</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the store</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word  entity\n",
       "22               school      53\n",
       "19           Moundville      37\n",
       "24                Selma      26\n",
       "5                Boston      23\n",
       "24            the river      18\n",
       "21                  Pa.      15\n",
       "5   Mrs. Pooley’s store      13\n",
       "35                 home      13\n",
       "9             the woods      12\n",
       "1             the store      11"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_places = oth_entity_count_df.append(place_df)\n",
    "top_places = combined_places.sort_values(by = 'entity', ascending = False).head(10)\n",
    "\n",
    "key_places = top_places['word'].unique().tolist()\n",
    "top_places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-quarter",
   "metadata": {},
   "source": [
    "### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "secondary-disposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['day', 'today', 'Christmas', 'June', 'summer', 'years', 'Thursday',\n",
       "       'Sunday', '15', 'tomorrow', 'July', 'February', 'August',\n",
       "       'yesterday', 'daily', '18', 'winter', 'months', '4673', '22',\n",
       "       'October', 'Sundays', 'November', 'Thanksgiving', 'Tuesday',\n",
       "       'Saturday', 'Monday', 'Weeks', 'Tomorrow', '1918', 'March',\n",
       "       'April', 'monthly', 'Friday', 'Yesterday', 'Tuesdays'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dates_df = df[df['entity'] == 'DATE']\n",
    "\n",
    "Dates_df['word'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sunrise-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lists to compare to when writing questions about Dates \n",
    "date_exclude = ['Weeks', 'day', 'Tomorrow', 'today','week', 'month', 'years','year']\n",
    "\n",
    "week_names = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October',  'November', 'December']\n",
    "\n",
    "cycles = ['daily', 'weekly', 'monthly', 'Annual', 'yearly', 'annually']\n",
    "\n",
    "seasons = ['winter', 'summer','spring','fall', 'autumn']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-demographic",
   "metadata": {},
   "source": [
    "### Relations & Opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "median-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "family_words = ['mother', 'father','dad', 'mom', 'uncle', 'sister', 'brother', 'parent',\n",
    "                'aunt','wife', 'husband', 'son', 'child', 'daughter', 'family']\n",
    "\n",
    "positive_relationships = ['friend','bestfriend', 'girlfriend','boyfriend','fiance']\n",
    "\n",
    "negative_relationshps = ['enemy', 'nemesis', 'villian', 'bully']\n",
    "\n",
    "relationship_words = family_words + positive_relationships + negative_relationshps\n",
    "\n",
    "positive_opinions = ['favorite', 'love', 'fantastic', 'awesome', 'wonderful','happy', 'superb', 'beautiful']\n",
    "\n",
    "negative_opinions = ['hate', 'distasteful', 'rude', 'ugly', 'disgusting', 'gross', 'dirty', 'mean']\n",
    "\n",
    "opinion_words = positive_opinions + negative_opinions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-retail",
   "metadata": {},
   "source": [
    "## Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "driving-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chapter = df.loc[(df['chapter_number'] ==  'Chapter '+ C_num)]\n",
    "\n",
    "sent_person_df = pd.DataFrame()\n",
    "ref_sentences = []\n",
    "for person in book1_characters:\n",
    "    sent_person_df = sent_person_df.append(df[df['word'] == person])\n",
    "    person_sentences = sent_person_df['sentence'].unique().tolist()\n",
    "    for place in key_places: \n",
    "        for sentence in person_sentences:\n",
    "            if place in sentence:\n",
    "                ref_sentences.append(sentence)\n",
    "\n",
    "unique_sentences = []\n",
    "for i in ref_sentences:\n",
    "    if i not in unique_sentences:\n",
    "        unique_sentences.append(i)\n",
    "\n",
    "polarity = []\n",
    "subjectivity = []\n",
    "assessment = []\n",
    "\n",
    "for  sentence in unique_sentences:\n",
    "    doc = nlp(sentence)\n",
    "    polarity.append(doc._.polarity)\n",
    "    subjectivity.append(doc._.subjectivity)\n",
    "    assessment.append(doc._.assessments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aquatic-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "white-guarantee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-e3d74a53e033>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentiment_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolarity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubjectivity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0massessment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'sentence'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'polarity'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'subjectivity'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'assessment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msentiment_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'polarity'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unique_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "sentiment_df = pd.DataFrame(list(zip(unique_sentences, polarity, subjectivity, assessment)), columns = ['sentence','polarity','subjectivity', 'assessment'])\n",
    "sentiment_df.sort_values(by = 'polarity', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "pleased-richardson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>\\n\\tI went to Mrs. Pooley’s store and bought the small rubber ball we used as the base for 5 cents.</td>\n",
       "      <td>-0.525000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>[([small], -0.25, 0.4, None), ([base], -0.8, 1.0, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>\\n      “I ain’t working for Mrs. Pooley no more,” I said casually, pretending to focus on my ma...</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>[([no, more], -0.25, 0.5, None), ([casually], -0.5000000000000001, 0.8666666666666667, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Dr. Griffith took her home, but it didn’t do no good.</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>[([no, good], -0.35, 0.6000000000000001, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Late that afternoon, me and Earl were helping Pa.</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>[([late], -0.3, 0.6, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>\\n      Mrs. Pooley was very pale as she stumbled out of the schoolhouse.</td>\n",
       "      <td>-0.273000</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>[([very, pale], -0.273, 0.23399999999999999, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\\n      \\n      On the way home, it seemed the Emma-joke had finally grown stale.</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[([finally], 0.0, 1.0, None), ([stale], -0.5, 0.5, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>We usually did our homework together while Mrs. Walker washed the dishes.</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>[([usually], -0.25, 0.25, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Thought about how I suddenly wasn’t sorry for beating up Bobby, even if it meant I had to sit al...</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[([suddenly], 0.0, 0.5, None), ([sorry], -0.5, 1.0, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>The last postmaster had been a lazy good-for-nothing; everyone had gotten the wrong mail two day...</td>\n",
       "      <td>-0.210000</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>[([last], 0.0, 0.06666666666666667, None), ([lazy], -0.25, 1.0, None), ([wrong], -0.5, 0.9, None...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Emma made me repeat just about every little thing that happened at school so she could learn it ...</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[([little], -0.1875, 0.5, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>After school, Mrs. Seay moved her desk aside and set up a little platform for Emma at the front ...</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[([little], -0.1875, 0.5, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Jim clutched my arm so tight it hurt and we started walking home.</td>\n",
       "      <td>-0.178571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>[([tight], -0.17857142857142858, 0.2857142857142857, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Those Yankees could…”\\n      “No one is going to burn down our school,” Mrs. Seay said firmly.</td>\n",
       "      <td>-0.177778</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>[([down], -0.15555555555555559, 0.2888888888888889, None), ([firmly], -0.2, 0.4, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Oh they knew about each other – Moundville ain’t that big and people talk – but Chip and Bobby h...</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>[([other], -0.125, 0.375, None), ([big], 0.0, 0.1, None), ([tired], -0.4, 0.7, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>“But enough about Treasure Island,” Emma said when we reached the curve in the riverbank that ma...</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[([enough], 0.0, 0.5, None), ([shallow], -0.3333333333333333, 0.5, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>\\n      “Mrs. Seay,” he said in his slow drawl, “this here’s a white school.”</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>[([slow], -0.30000000000000004, 0.39999999999999997, None), ([white], 0.0, 0.0, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>\\n      We followed Mrs. Pooley ‘round the side of the store to the wooden staircase that went u...</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>[([round], -0.2, 0.4, None), ([wooden], 0.0, 0.0, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Wilson school was two miles away, so when Mrs. Seay let us out the next day, I sat down unde...</td>\n",
       "      <td>-0.077778</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>[([next], 0.0, 0.0, None), ([down], -0.15555555555555559, 0.2888888888888889, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Next to Dr. Griffith’s house was a tiny little cabin that he rented out to the schoolteacher.</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[([next], 0.0, 0.0, None), ([tiny], 0.0, 0.5, None), ([little], -0.1875, 0.5, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>A moment later, Mrs. Seay came out of the schoolhouse and sat down next to us.</td>\n",
       "      <td>-0.051852</td>\n",
       "      <td>0.096296</td>\n",
       "      <td>[([later], 0.0, 0.0, None), ([down], -0.15555555555555559, 0.2888888888888889, None), ([next], 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                sentence  polarity  subjectivity                                                                                           assessment\n",
       "75   \\n\\tI went to Mrs. Pooley’s store and bought the small rubber ball we used as the base for 5 cents. -0.525000      0.700000                                             [([small], -0.25, 0.4, None), ([base], -0.8, 1.0, None)]\n",
       "81   \\n      “I ain’t working for Mrs. Pooley no more,” I said casually, pretending to focus on my ma... -0.375000      0.683333        [([no, more], -0.25, 0.5, None), ([casually], -0.5000000000000001, 0.8666666666666667, None)]\n",
       "106                                                Dr. Griffith took her home, but it didn’t do no good. -0.350000      0.600000                                                      [([no, good], -0.35, 0.6000000000000001, None)]\n",
       "61                                                     Late that afternoon, me and Earl were helping Pa. -0.300000      0.600000                                                                          [([late], -0.3, 0.6, None)]\n",
       "68                             \\n      Mrs. Pooley was very pale as she stumbled out of the schoolhouse. -0.273000      0.234000                                                  [([very, pale], -0.273, 0.23399999999999999, None)]\n",
       "32                     \\n      \\n      On the way home, it seemed the Emma-joke had finally grown stale. -0.250000      0.750000                                            [([finally], 0.0, 1.0, None), ([stale], -0.5, 0.5, None)]\n",
       "47                             We usually did our homework together while Mrs. Walker washed the dishes. -0.250000      0.250000                                                                     [([usually], -0.25, 0.25, None)]\n",
       "122  Thought about how I suddenly wasn’t sorry for beating up Bobby, even if it meant I had to sit al... -0.250000      0.750000                                           [([suddenly], 0.0, 0.5, None), ([sorry], -0.5, 1.0, None)]\n",
       "70   The last postmaster had been a lazy good-for-nothing; everyone had gotten the wrong mail two day... -0.210000      0.713333  [([last], 0.0, 0.06666666666666667, None), ([lazy], -0.25, 1.0, None), ([wrong], -0.5, 0.9, None...\n",
       "8    Emma made me repeat just about every little thing that happened at school so she could learn it ... -0.187500      0.500000                                                                     [([little], -0.1875, 0.5, None)]\n",
       "13   After school, Mrs. Seay moved her desk aside and set up a little platform for Emma at the front ... -0.187500      0.500000                                                                     [([little], -0.1875, 0.5, None)]\n",
       "110                                    Jim clutched my arm so tight it hurt and we started walking home. -0.178571      0.285714                                          [([tight], -0.17857142857142858, 0.2857142857142857, None)]\n",
       "114       Those Yankees could…”\\n      “No one is going to burn down our school,” Mrs. Seay said firmly. -0.177778      0.344444              [([down], -0.15555555555555559, 0.2888888888888889, None), ([firmly], -0.2, 0.4, None)]\n",
       "124  Oh they knew about each other – Moundville ain’t that big and people talk – but Chip and Bobby h... -0.175000      0.391667                [([other], -0.125, 0.375, None), ([big], 0.0, 0.1, None), ([tired], -0.4, 0.7, None)]\n",
       "24   “But enough about Treasure Island,” Emma said when we reached the curve in the riverbank that ma... -0.166667      0.500000                            [([enough], 0.0, 0.5, None), ([shallow], -0.3333333333333333, 0.5, None)]\n",
       "119                        \\n      “Mrs. Seay,” he said in his slow drawl, “this here’s a white school.” -0.150000      0.200000               [([slow], -0.30000000000000004, 0.39999999999999997, None), ([white], 0.0, 0.0, None)]\n",
       "82   \\n      We followed Mrs. Pooley ‘round the side of the store to the wooden staircase that went u... -0.100000      0.200000                                             [([round], -0.2, 0.4, None), ([wooden], 0.0, 0.0, None)]\n",
       "11   The Wilson school was two miles away, so when Mrs. Seay let us out the next day, I sat down unde... -0.077778      0.144444                 [([next], 0.0, 0.0, None), ([down], -0.15555555555555559, 0.2888888888888889, None)]\n",
       "94         Next to Dr. Griffith’s house was a tiny little cabin that he rented out to the schoolteacher. -0.062500      0.333333                 [([next], 0.0, 0.0, None), ([tiny], 0.0, 0.5, None), ([little], -0.1875, 0.5, None)]\n",
       "120                       A moment later, Mrs. Seay came out of the schoolhouse and sat down next to us. -0.051852      0.096296  [([later], 0.0, 0.0, None), ([down], -0.15555555555555559, 0.2888888888888889, None), ([next], 0..."
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.sort_values(by = 'polarity', ascending = True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-score",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "vital-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a combination of location, dates, and characters to check basic reading comparhension\n",
    "\n",
    "#Question about peoples relationships to other people\n",
    "person1 = ''\n",
    "person2 = ''\n",
    "place = ''\n",
    "date = ''\n",
    "q_format_1 = 'How does {} feel about {}'.format(person1, person2)\n",
    "q_format_2 = 'Who is {} to {} in the chapter'.format(person1, person2)\n",
    "\n",
    "#Questions about people in relation to places\n",
    "q_format_3 = 'What did {} do at {}'.format(person1, place)\n",
    "\n",
    "#Questions about people feel about places\n",
    "q_format_4 = 'How does {} feel about {}'.format(person1, place)\n",
    "\n",
    "#Questions about dates and people\n",
    "\n",
    "q_format_5 =  'Who was talking what happens on {}?'.format(date)\n",
    "q_format_6 =  'What happens what happens on {}?'.format(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "regional-hygiene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emma',\n",
       " 'Walker',\n",
       " 'Sims',\n",
       " 'Dit',\n",
       " 'Ollie',\n",
       " 'Ulman',\n",
       " 'Elman',\n",
       " 'Raymond',\n",
       " 'Earl',\n",
       " 'Pearl',\n",
       " 'Robert',\n",
       " 'Lois',\n",
       " 'Pooley',\n",
       " 'Wiggens',\n",
       " 'Elbert',\n",
       " 'Davidson',\n",
       " 'Haley',\n",
       " 'Griffith',\n",
       " 'Jim',\n",
       " 'Dang',\n",
       " 'Mitch',\n",
       " 'Seay',\n",
       " 'Bobby',\n",
       " 'Mary']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book1_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "designing-spirit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['school',\n",
       " 'Moundville',\n",
       " 'Selma',\n",
       " 'Boston',\n",
       " 'the river',\n",
       " 'Pa.',\n",
       " 'Mrs. Pooley’s store',\n",
       " 'home',\n",
       " 'the woods',\n",
       " 'the store']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "hairy-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_generator (chapter, narrator):\n",
    "    \n",
    "    df_chapter = df.loc[(df['chapter_number'] ==  'Chapter '+ str(chapter))]\n",
    "    isnarrator = False\n",
    "    if narrator.lower() == 'yes':\n",
    "        isnarrator == True\n",
    "    else:\n",
    "        isnarrator == False\n",
    "        \n",
    "        \n",
    "    sent_person_df = pd.DataFrame()\n",
    "    ref_sentences = []\n",
    "                         \n",
    "    \n",
    "    for person in book1_characters:\n",
    "        sent_person_df = sent_person_df.append(df_chapter[df_chapter['word'] == person])\n",
    "        person_sentences = sent_person_df['sentence'].unique().tolist()\n",
    "        \n",
    "        #Person to place                 \n",
    "        for place in key_places: \n",
    "            for sentence in person_sentences:\n",
    "                if place in sentence:\n",
    "                    ref_sentences.append(sentence)\n",
    "        \n",
    "        #person to person\n",
    "        for person1 in book1_characters:\n",
    "            for person2 in book1_characters:\n",
    "                if person1 == person2:\n",
    "                    pass\n",
    "                else:\n",
    "                    for sentence in person_sentences:\n",
    "                        if person1 in sentence and person2 in sentence:\n",
    "                            ref_sentences.append(sentence)\n",
    "    unique_sentences = []\n",
    "    for i in ref_sentences:\n",
    "        if i not in unique_sentences:\n",
    "            unique_sentences.append(i)\n",
    "        \n",
    "    #questions to generate\n",
    "    question_list = []\n",
    "    for sentences in unique_sentences:\n",
    "        for word in relationship_words:\n",
    "            if word in sentence:\n",
    "                \n",
    "                \n",
    "    return unique_sentences\n",
    "                         \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cosmetic-hungary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I tell you things were fine in Moundville before Emma got here, least I thought they were.',\n",
       " 'But I ain’t never been so wrong as I was about Emma Walker.',\n",
       " 'The evening Emma came, Mrs. Pooley sat in her usual rocker, smoking a pipe with Uncle Wiggens.',\n",
       " 'My real name is Harry Otis Sims, but everybody calls me Dit.',\n",
       " 'With so many kids, sometimes I think my pa don’t even know my name, since it’s always, “Della, Ollie, Ulman, Elman, Raymond, uh, I mean Dit.”',\n",
       " 'There are ten children in our family: Della, Ollie, Ulman, Elman, Raymond, me, Earl, Pearl, Robert and Lois.',\n",
       " ' ‘Course if I’d had the money I could have bought a new ball at Mrs. Pooley’s store, but if you wind twine real careful, it’s almost as good as a real ball.',\n",
       " 'The last postmaster had been a lazy good-for-nothing; everyone had gotten the wrong mail two days late, ‘til he had finally skipped town for refusing to pay his debts at Mrs. Pooley’s store.']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_generator(1, 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-filter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
